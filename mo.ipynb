{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::(anonymous namespace)::CvtHelper<cv::impl::(anonymous namespace)::Set<3, 4, -1>, cv::impl::(anonymous namespace)::Set<3, -1, -1>, cv::impl::(anonymous namespace)::Set<0, 5, -1>, cv::impl::(anonymous namespace)::NONE>::CvtHelper(cv::InputArray, cv::OutputArray, int) [VScn = cv::impl::(anonymous namespace)::Set<3, 4, -1>, VDcn = cv::impl::(anonymous namespace)::Set<3, -1, -1>, VDepth = cv::impl::(anonymous namespace)::Set<0, 5, -1>, sizePolicy = cv::impl::(anonymous namespace)::NONE]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f6db066f01f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/mohamedwalid/Desktop/Semester 7/Computer vision/CV-main/Test Cases-20241123\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mprocess_test_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_image_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-f6db066f01f7>\u001b[0m in \u001b[0;36mprocess_test_cases\u001b[0;34m(image_folder, special_image_index)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mcleaned_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mcropped_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Cropped_{file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcropped_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-f6db066f01f7>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Detect and remove hand after preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mhand_removed_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_denoised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhand_removed_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhand_removed_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-f6db066f01f7>\u001b[0m in \u001b[0;36mremove_hand\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mDetects\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mremoves\u001b[0m \u001b[0mhand\u001b[0m \u001b[0mregions\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m \u001b[0musing\u001b[0m \u001b[0minpainting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mensures\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbarcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mintact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mhsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Define a comprehensive skin color range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::(anonymous namespace)::CvtHelper<cv::impl::(anonymous namespace)::Set<3, 4, -1>, cv::impl::(anonymous namespace)::Set<3, -1, -1>, cv::impl::(anonymous namespace)::Set<0, 5, -1>, cv::impl::(anonymous namespace)::NONE>::CvtHelper(cv::InputArray, cv::OutputArray, int) [VScn = cv::impl::(anonymous namespace)::Set<3, 4, -1>, VDcn = cv::impl::(anonymous namespace)::Set<3, -1, -1>, VDepth = cv::impl::(anonymous namespace)::Set<0, 5, -1>, sizePolicy = cv::impl::(anonymous namespace)::NONE]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def clean(img: np.ndarray, margin: int = 20) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Crops the barcode region from the image based on contours.\n",
    "    \"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, thresholded = cv.threshold(img, 128, 255, cv.THRESH_BINARY_INV)\n",
    "    contours, _ = cv.findContours(thresholded, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return img  # Return the original image if no contours are found\n",
    "\n",
    "    x_min = min(cv.boundingRect(c)[0] for c in contours)\n",
    "    x_max = max(cv.boundingRect(c)[0] + cv.boundingRect(c)[2] for c in contours)\n",
    "    _, y, _, h = cv.boundingRect(max(contours, key=cv.contourArea))\n",
    "\n",
    "    cropped_img = img[y:y + h, x_min:x_max]\n",
    "    cropped_img[-margin:, :] = 255  # Set the bottom margin to white\n",
    "\n",
    "    return cropped_img\n",
    "\n",
    "\n",
    "def preprocess_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocesses the image by applying grayscale conversion, thresholding, \n",
    "    and then removing the hand at the end.\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "\n",
    "    # Ensure the image is in grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img_gray = img\n",
    "\n",
    "    # Apply further preprocessing\n",
    "    img_blurred = cv.medianBlur(cv.blur(img_gray, (3, 3)), 3)\n",
    "    _, img_denoised = cv.threshold(img_blurred, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define HSV thresholds for detecting hand regions (skin tone)\n",
    "    lower_skin1 = np.array([0, 20, 50], dtype=np.uint8)\n",
    "    upper_skin1 = np.array([25, 170, 255], dtype=np.uint8)\n",
    "    lower_skin2 = np.array([160, 20, 50], dtype=np.uint8)\n",
    "    upper_skin2 = np.array([180, 170, 255], dtype=np.uint8)\n",
    "\n",
    "    # Create masks for skin tone detection\n",
    "    mask1 = cv.inRange(hsv, lower_skin1, upper_skin1)\n",
    "    mask2 = cv.inRange(hsv, lower_skin2, upper_skin2)\n",
    "    skin_mask = cv.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Check if skin regions (hand) are detected\n",
    "    if cv.countNonZero(skin_mask) > 1000:  # Adjust the threshold as needed\n",
    "        img_denoised = remove_hand(img)\n",
    "        \n",
    "\n",
    "    return img_denoised\n",
    "\n",
    "\n",
    "\n",
    "def remove_hand(img: np.ndarray) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Detects and removes hand regions from the image using inpainting, and ensures the barcode is intact.\n",
    "    \"\"\"\n",
    "    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define a comprehensive skin color range\n",
    "    lower_skin1 = np.array([0, 20, 50], dtype=np.uint8)\n",
    "    upper_skin1 = np.array([25, 170, 255], dtype=np.uint8)\n",
    "    lower_skin2 = np.array([160, 20, 50], dtype=np.uint8)\n",
    "    upper_skin2 = np.array([180, 170, 255], dtype=np.uint8)\n",
    "\n",
    "    # Create two masks to cover the skin color range\n",
    "    mask1 = cv.inRange(hsv, lower_skin1, upper_skin1)\n",
    "    mask2 = cv.inRange(hsv, lower_skin2, upper_skin2)\n",
    "    skin_mask = cv.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Morphological operations to remove noise and close gaps\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
    "    skin_mask = cv.morphologyEx(skin_mask, cv.MORPH_CLOSE, kernel, iterations=2)\n",
    "    skin_mask = cv.morphologyEx(skin_mask, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # Find contours in the skin mask\n",
    "    contours, _ = cv.findContours(skin_mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return img  # Return the original image if no hand is detected\n",
    "\n",
    "    # Assume the largest contour is the hand\n",
    "    largest_contour = max(contours, key=cv.contourArea)\n",
    "\n",
    "    # Create a mask for the hand\n",
    "    hand_mask = np.zeros_like(skin_mask)\n",
    "    cv.drawContours(hand_mask, [largest_contour], -1, 255, thickness=cv.FILLED)\n",
    "\n",
    "    # Invert the hand mask to prepare for inpainting\n",
    "    hand_mask_inv = cv.bitwise_not(hand_mask)\n",
    "\n",
    "    # Remove the hand using inpainting\n",
    "    img_no_hand = cv.inpaint(img, hand_mask, inpaintRadius=3, flags=cv.INPAINT_TELEA)\n",
    "\n",
    "    # Repair barcode area\n",
    "    gray = cv.cvtColor(img_no_hand, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 1: Erosion to remove small artifacts\n",
    "    erosion_kernel = cv.getStructuringElement(cv.MORPH_RECT, (1, 50))  # Smaller height for precise artifact removal\n",
    "    binary_erode = cv.erode(gray, erosion_kernel, iterations=2)  # Increased iterations for stronger effect\n",
    "\n",
    "    # Step 2: Dilation to restore barcode lines\n",
    "    dilation_kernel = cv.getStructuringElement(cv.MORPH_RECT, (1, 60))  # Matching or slightly larger kernel\n",
    "    binary_opened = cv.dilate(binary_erode, dilation_kernel, iterations=3)  # Increased iterations for better line restoration\n",
    "\n",
    "    # Step 3: Fine adjustment using another dilation\n",
    "    dilationkernel2 = cv.getStructuringElement(cv.MORPH_RECT, (1, 10))  # Smaller kernel for final touch\n",
    "    binary_final = cv.dilate(binary_opened, dilationkernel2, iterations=2)\n",
    "\n",
    "    # Step 4: Smoothing with a vertical filter\n",
    "    kernel = np.ones((30, 1), np.float32) / 30  # Reduced kernel size for finer filtering\n",
    "    vertical_mean_filtered = cv.filter2D(binary_final, -1, kernel)\n",
    "\n",
    "    # Step 5: Normalize to ensure pixel intensities are correct\n",
    "    img = cv.normalize(vertical_mean_filtered, None, 0, 255, cv.NORM_MINMAX)\n",
    "\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def display_before_after(\n",
    "    original_img: np.ndarray, cropped_img: np.ndarray, title_before: str = \"Original Image\",\n",
    "    title_after: str = \"Cropped Barcode\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays the original and processed images side by side.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    images = [(original_img, title_before), (cropped_img, title_after)]\n",
    "    for i, (img, title) in enumerate(images):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        plt.imshow(img if len(img.shape) == 2 else cv.cvtColor(img, cv.COLOR_BGR2RGB),\n",
    "                   cmap='gray' if len(img.shape) == 2 else None)\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def process_test_cases(image_folder: str, special_image_index: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Processes test cases by cleaning and cropping barcodes from images in the folder.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(image_folder) if f.endswith(\".jpg\")]\n",
    "    files.sort(key=lambda x: int(os.path.splitext(x)[0].split()[0]))\n",
    "    output_folder = os.path.join(image_folder, \"Processed_Output\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for i, file_name in enumerate(files):\n",
    "        image_path = os.path.join(image_folder, file_name)\n",
    "        original_img = cv.imread(image_path)\n",
    "        if original_img is None:\n",
    "            print(f\"Could not read image {file_name}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        cleaned_img = preprocess_image(original_img)\n",
    "        cropped_img = clean(cleaned_img)\n",
    "        cv.imwrite(os.path.join(output_folder, f\"Cropped_{file_name}\"), cropped_img)\n",
    "        display_before_after(original_img, cropped_img)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"/Users/mohamedwalid/Desktop/Semester 7/Computer vision/CV-main/Test Cases-20241123\"\n",
    "    process_test_cases(folder, special_image_index=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded barcode: Stop/Start1234567890-Stop/Start\n",
      "Decoded barcode: Stop/Start104-116-116Stop/Start\n",
      "Decoded barcode: Stop/Start112-115-58-Stop/Start\n",
      "Decoded barcode: Stop/Start-47-47-121-Stop/Start\n",
      "Decoded barcode: Stop/Start111-117-116Stop/Start\n",
      "Decoded barcode: Stop/Start-117-46-98-Stop/Start\n",
      "Decoded barcode: \n",
      "Decoded barcode: Stop/Start113-119-52-Stop/Start\n",
      "Decoded barcode: \n",
      "Decoded barcode: Stop/Start103-120-99-Stop/Start\n",
      "Decoded barcode: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def decoder(your_cropped_image):\n",
    "    \"\"\"\n",
    "    Decodes a Code 11 barcode from a cropped image.\n",
    "    \n",
    "    Args:\n",
    "        your_cropped_image (numpy.ndarray): The cropped barcode image in grayscale.\n",
    "        \n",
    "    Returns:\n",
    "        list: Decoded digits as a list of strings, excluding 'Stop/Start'.\n",
    "    \"\"\"\n",
    "    # 0 means narrow, 1 means wide\n",
    "    NARROW = \"0\"\n",
    "    WIDE = \"1\"\n",
    "    code11_widths = {\n",
    "        \"00110\": \"Stop/Start\",\n",
    "        \"10001\": \"1\",\n",
    "        \"01001\": \"2\",\n",
    "        \"11000\": \"3\",\n",
    "        \"00101\": \"4\",\n",
    "        \"10100\": \"5\",\n",
    "        \"01100\": \"6\",\n",
    "        \"00011\": \"7\",\n",
    "        \"10010\": \"8\",\n",
    "        \"10000\": \"9\",\n",
    "        \"00001\": \"0\",\n",
    "        \"00100\": \"-\",\n",
    "    }\n",
    "\n",
    "    # Get the average of each column in your image\n",
    "    mean = your_cropped_image.mean(axis=0)\n",
    "\n",
    "    # Set it to black or white based on its value\n",
    "    mean[mean <= 127] = 1\n",
    "    mean[mean > 128] = 0\n",
    "\n",
    "    # Convert to string of pixels in order to loop over it\n",
    "    pixels = ''.join(mean.astype(np.uint8).astype(str))\n",
    "\n",
    "    # Need to figure out how many pixels represent a narrow bar\n",
    "    narrow_bar_size = 0\n",
    "    for pixel in pixels:\n",
    "        if pixel == \"1\":\n",
    "            narrow_bar_size += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    wide_bar_size = narrow_bar_size * 2\n",
    "\n",
    "    digits = []\n",
    "    pixel_index = 0\n",
    "    current_digit_widths = \"\"\n",
    "    skip_next = False\n",
    "\n",
    "    while pixel_index < len(pixels):\n",
    "\n",
    "        if skip_next:\n",
    "            pixel_index += narrow_bar_size\n",
    "            skip_next = False\n",
    "            continue\n",
    "\n",
    "        count = 1\n",
    "        try:\n",
    "            while pixels[pixel_index] == pixels[pixel_index + 1]:\n",
    "                count += 1\n",
    "                pixel_index += 1\n",
    "        except:\n",
    "            pass\n",
    "        pixel_index += 1\n",
    "\n",
    "        current_digit_widths += NARROW if count == narrow_bar_size else WIDE\n",
    "\n",
    "        if current_digit_widths in code11_widths:\n",
    "            digits.append(code11_widths[current_digit_widths])\n",
    "            current_digit_widths = \"\"\n",
    "            skip_next = True  # Next iteration will be a separator, so skip it\n",
    "\n",
    "    return digits\n",
    "\n",
    "cropped_image_path_Folder = '/Users/mohamedwalid/Desktop/Semester 7/Computer vision/CV-main/Test Cases-20241123/Processed_Output'\n",
    "\n",
    "# Get a sorted list of image files\n",
    "cropped_images = sorted(os.listdir(cropped_image_path_Folder))\n",
    "\n",
    "for cropped_image in cropped_images:\n",
    "    cropped_image_path = os.path.join(cropped_image_path_Folder, cropped_image)\n",
    "    cropped_img = cv.imread(cropped_image_path, cv.IMREAD_GRAYSCALE)\n",
    "    if cropped_img is not None:\n",
    "        decoded_digits = decoder(cropped_img)\n",
    "        print(\"Decoded barcode:\", ''.join(decoded_digits))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
